<!DOCTYPE html>
<html>
<head>
	<title>Deep Learning for Garbage Segregation</title>
</head>
<body class="user-details">
	<p>We produce unbelievable amounts of garbage and still do not have proper measures in place to deal with it. The amount of waste generated has tripled since 1960, leading to devastating effects for the environment. Segregating waste for further processing is the first major bottleneck in the recycling process. This task is usually carried out by hand. Automating it would greatly help reduce the cost and time taken to recycle items.

This project aims to solve the fundamental problem of waste segregation using <b>Deep Learning</b>. We want to develop Computer Vision technologies that can classify the category that individual garbage pieces belong to. This can then be implemented in smart waste disposal systems, either in the form of smart bin that immediately sorts garbage into the category it belongs, or as a additional module in existing garbage processing facilities.</p>
<h2>Work Done So Far</h2>
<h3>Literature Review</h3>
<p> Looked into existing smart waste disposal systems and identified potential improvements that could be made. Shortlisted various Image processing and Deep Learning techniques that may help us.</p>
<h3>Initial Dataset</h3>
<p>
 Dataset was btained from the trashnet Github repository (https://github.com/garythung/trashnet). Contains images split into 6 different classes: glass, paper, cardboard, plastic, metal, and other trash . Currently, the dataset consists of 2527 images: 
 <ul><li>
 	501 glass 
 </li>
<li>
	594 paper
</li>
<li>
	482 plastic
</li>
<li>
	410 metal 
</li>
<li>
	137 trash
</li></ul>
 The pictures were taken by placing the object on a white poster-board and using sunlight and/or room lighting . The pictures have been resized down to 512 x 384. The devices used were Apple iPhone 7 Plus, Apple iPhone 5S, and Apple iPhone SE. </p>
<h3>
	Model v1
</h3>
<p>
	We attempted training our dataset on existing Neural architectures (such as VGG19). However due to computational constraints this approach was soon abandoned. We tried training the data on simple CNNs built from scratch but the accuracy was too low.
</p>
<h3>Model v2</h3>
<p>
We decided to use Transfer Learning as the primary approach for designing our model. Used Resnet50 pretrained on Imagenet and used Pytorch to retrain the final layer on our dataset. This gave us a very good test accuracy of 94%. This could be improved further with a better base model and by finetuning our hyperparameters.
!["Confusion Matrix"]("projects/proj-1/cm.png")
<!--
	add f1 score
--></p>
<h3>Model Demo Frontend</h3>
<p>Deployed our model to a simple [website](https://recycle.onrender.com) that can be used for demonstration and testing. 
<!---
pic of ui
-->
</p>
<h2>Designing a Smart Bin Prototype</h2>
<p>The high level idea was that we wanted the user experience to be identical to if they were using a regular bin.</p>
<h3>
	Hardware Used for Prototype
</h3>
<ul>
	<li>Raspberry Pi 3B</li>
	<li>720p Camera Module</li>
	<li>Infrared sensors</li>
	<li>Servo motors</li>
	<li>Connecting Cables</li>
	<li>Battery Pack</li>
</ul>
<h3>
	Proposed Working of a Smart Bin
</h3>
<ol>
	<li>The user drops the garbage object into the smart bin.</li>
	<li>It lands on a staging area where a camera is focussed.</li>
	<li>A motion detection script running on the microcontroller triggers the image classification algorithm.</li>
	<li>The image classification algorithm runs locally and assigns a label to the object.</li>
	<li>The microcontroller then instructs the servo motors on the correct alignment. It then uploads the image and the corresponding label to the database in the cloud.</li>
	<li>The staging area drops and the servo motors guide the object to the area that corresponds to the assigned label. </li>
</ol>
	<p>Periodically infrared sensors check whether the dustbin is at capacity. If so, an alert is sent to the backend. This can be used for route planning.</p>

<h3>Model v3</h3>
<p>Running our model on the Raspberry Pi to classify images in real-time was impractical. The Pi would heat up and would take too long to predict the class of an image. Due to computational constraints we had to sacrifice accuracy for speed and created a new model by performing Transfer Learning on MobileNet v2. We then exported this to a Ternsorflow Lite model. This resulted in our model classifying our images almost instantaneously, although accuracy was affected. Hopefully accuracy can be improved with hyperparameter tuning and dataset augmentation.</p>

<h3>Dataset Augmentation</h3>
<p>
After every classification the image, coresponding label and a timestamp is sent to a Firebase database. This allows us to retrain our model on images taken by our camera in our lighting and background conditions, which should significantly improve our accuracy.</p>
<h3>Evaluation Metrics</h3>
</body>
</html>